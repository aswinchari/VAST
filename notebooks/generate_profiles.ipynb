{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/kwagstyl/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/users/kwagstyl/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import io_mesh as io\n",
    "import subprocess\n",
    "import argparse\n",
    "import os\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import glob\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def chunks(l, n):\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]\n",
    "\n",
    "# TODO replace with function from io_mesh?\n",
    "def load_surface(surfname):\n",
    "    \"\"\"Loads obj surface.\n",
    "    Returns:\n",
    "        n_vert (int, number of vertices)\n",
    "        coords, \n",
    "        normals, \n",
    "        triangles\n",
    "    \"\"\"\n",
    "    polys=[]\n",
    "    p=0\n",
    "    k=0\n",
    "    with open(surfname, 'r') as fp:\n",
    "        for i, line in enumerate(fp):\n",
    "            if i==0:\n",
    "                # Number of vertices\n",
    "                line1 = line.split()\n",
    "                n_vert = int(line1[6])\n",
    "                coords = np.zeros([ n_vert, 3])\n",
    "                norms = np.zeros([ n_vert, 3])\n",
    "            elif 0 < i < n_vert+1:\n",
    "                # get coordinates\n",
    "                coords[ i-1 ] = list(map( float, line.split() ))\n",
    "            elif n_vert+1 < i < 2*n_vert + 2:\n",
    "                # get normals (we just write them back out, not recomputing)\n",
    "                norms[p]=line.split()\n",
    "                p+=1\n",
    "            elif i==2*n_vert+3:\n",
    "                # get number of polygons. Not needed any more\n",
    "                n_poly=int(line)\n",
    "            elif i==2*n_vert+4:\n",
    "                # get colour info\n",
    "                col=line\n",
    "            elif i>2*n_vert+5 and k==0:\n",
    "                if not line.strip():\n",
    "                    k=1\n",
    "            elif k==1:\n",
    "                # get polygons\n",
    "                polys.extend(line.split())\n",
    "    polys = list(map(int,polys))\n",
    "    tris = list(chunks(polys,3))\n",
    "    return n_vert, coords, norms, tris;\n",
    "\n",
    "def load_intensities(intensity_file):\n",
    "    with open(intensity_file,'r') as f:\n",
    "            for n in range(4): \n",
    "                f.readline()\n",
    "            lst=f.readline().split('\\t')[1:-1]\n",
    "            vector=[]\n",
    "            for i in lst:\n",
    "                try:\n",
    "                    vector.append(float(i))\n",
    "                except ValueError:\n",
    "                    vector.append(0)          \n",
    "    return vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "surf_dir='/data1/users/kwagstyl/bigbrain/VAST/surface_data/obj_surfaces/'\n",
    "profile_dir='/data1/users/kwagstyl/bigbrain/VAST/surface_data/profile_data/'\n",
    "bin_dir='/data1/users/kwagstyl/quarantines/Linux-x86_64/bin/'\n",
    "vol_dir='/data1/users/kwagstyl/bigbrain/volumes/'\n",
    "os.makedirs(surf_dir, exist_ok=True)\n",
    "os.makedirs(profile_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate blocks to sample from legend1000.mnc, a volume containing block indices\n",
    "hemis=['right','left']\n",
    "for hemi in hemis:\n",
    "    subprocess.call('{} -nearest_neighbour {} {} {}'.format(os.path.join(bin_dir,'volume_object_evaluate'),\n",
    "                                                    os.path.join(vol_dir,'legend1000.mnc'),\n",
    "                                                    os.path.join(surf_dir,'gray_{}.obj'.format(hemi)),\n",
    "                                                    os.path.join(profile_dir,'block_to_sample_{}.txt'.format(hemi))),\n",
    "    shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating equidistant coordinates\n"
     ]
    }
   ],
   "source": [
    "#generate equidistant profiles\n",
    "smoothings=['geo','raw']\n",
    "n_surfs=200\n",
    "for hemi in hemis:\n",
    "    print('generating equidistant coordinates')\n",
    "    n_vert, white_coords, d, d =load_surface(os.path.join(surf_dir,'white_{}.obj'.format(hemi)))\n",
    "    n_vert, gray_coords, d, d =load_surface(os.path.join(surf_dir,'gray_{}.obj'.format(hemi)))\n",
    "    vector=(white_coords-gray_coords)/(n_surfs-1)\n",
    "    hemi_coords=np.zeros((n_surfs,n_vert,3))\n",
    "    hemi_intensities=np.zeros((n_surfs,n_vert))\n",
    "    for surf_index in range(n_surfs):\n",
    "        hemi_coords[surf_index]=gray_coords+vector*surf_index\n",
    "        \n",
    "        \n",
    "    \n",
    "    blocks=np.loadtxt(os.path.join(profile_dir,'block_to_sample_{}.txt'.format(hemi))).astype(int)\n",
    "    hemi_blocks=np.unique(blocks)\n",
    "    for smoothing in smoothings:\n",
    "        print('sampling {} blocks'.format(smoothing))\n",
    "        for block in hemi_blocks:\n",
    "            print('sampling block:{}'.format(block))\n",
    "            block_coordinates=hemi_coords[:,blocks==block,:]\n",
    "            verts_in_block=block_coordinates.shape[1]\n",
    "        #reshape into streamlines\n",
    "            block_hemi_coords_streamlines=np.reshape(block_coordinates,(n_surfs*verts_in_block,3),order='F')\n",
    "        #write out streamlines into txt file\n",
    "            np.savetxt(os.path.join(profile_dir,'coordinates_block.txt'),block_hemi_coords_streamlines)\n",
    "        #sample streamlines from block (dummy with full low res first)\n",
    "            if smoothing == 'geo':\n",
    "                glimfile = ' /data1/users/kwagstyl/bigbrain/blocks20/block20-{0:0>4}_geo.mnc\\n'.format(block)\n",
    "                txtname='_geo'\n",
    "            else:\n",
    "                glimfile = ' /data1/users/kwagstyl/bigbrain/blocks20/block20-{0:0>4}.mnc\\n'.format(block)\n",
    "                txtname=''\n",
    "            #glimfile=' /data1/users/kwagstyl/bigbrain/volumes/full8_300um.mnc\\n'\n",
    "            dumglim = ' /data1/users/kwagstyl/bigbrain/volumes/full8_1000um.mnc\\n'\n",
    "            with open(os.path.join(profile_dir,'glimblock'),'w') as f:\n",
    "                f.write(dumglim+glimfile)\n",
    "            subprocess.call('{} {} {} {} >/dev/null'.format(os.path.join(bin_dir,'print_world_values'),\n",
    "                                                                                            os.path.join(profile_dir,'glimblock'),\n",
    "                                                                                            os.path.join(profile_dir,'coordinates_block.txt'),\n",
    "                                                                                            os.path.join(profile_dir,'block_values_{0:0>4}{1}.txt'.format(block,txtname))\n",
    "                                                                                            ),shell=True)\n",
    "              #import profiles for block, put into overall profiles matrix\n",
    "            block_intensities=load_intensities(os.path.join(profile_dir,'block_values_{0:0>4}{1}.txt'.format(block,txtname)))\n",
    "            hemi_intensities[:,blocks[:n_vert]==block]=np.reshape(block_intensities,(n_surfs,verts_in_block),order='F')\n",
    "        #save out overall profiles matrix\n",
    "        np.savetxt(os.path.join(profile_dir,'euclid_{}_profiles_{}.txt'.format(smoothing,hemi)),hemi_intensities.T,fmt='%.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating coordinates\n",
      "sampling blocks\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n"
     ]
    }
   ],
   "source": [
    "#generate coordinates, TODO\n",
    "for hemi in hemis:\n",
    "    smoothing=''\n",
    "    print('generating coordinates')\n",
    "    n_vert=163842\n",
    "    n_surfs=200\n",
    "    hemi_coords=np.zeros((n_surfs,n_vert,3))\n",
    "    hemi_intensities=np.zeros((n_surfs,n_vert))\n",
    "    surf_refs=np.linspace(0,1,n_surfs)\n",
    "    surf_names=sorted(glob.glob('equivolume_surfaces/equi_volume_'+hemi+'*'))\n",
    "    for surf_index in range(n_surfs):\n",
    "        surfname=surf_names[surf_index]\n",
    "        hemi_coords[surf_index]=load_coords(surfname,n_vert)\n",
    "#generate block coordinates\n",
    "    print('sampling blocks')\n",
    "    blocks=np.loadtxt('block_to_sample_'+hemi+'.txt').astype(int)\n",
    "    hemi_blocks=np.unique(blocks[:n_vert])\n",
    "    for block in hemi_blocks:\n",
    "        print(block)\n",
    "        block_coordinates=hemi_coords[:,blocks[:n_vert]==block,:]\n",
    "        verts_in_block=block_coordinates.shape[1]\n",
    "    #reshape into streamlines\n",
    "        block_hemi_coords_streamlines=np.reshape(block_coordinates,(n_surfs*verts_in_block,3),order='F')\n",
    "    #write out streamlines into txt file\n",
    "        np.savetxt('coordinates_block.txt',block_hemi_coords_streamlines)\n",
    "    #sample streamlines from block (dummy with full low res first)\n",
    "        if smoothing == 'geo':\n",
    "            glimfile = ' /data1/users/kwagstyl/bigbrain/blocks20/block20-{0:0>4}_geo.mnc\\n'.format(block)\n",
    "            txtname='_geo'\n",
    "        else:\n",
    "            glimfile = ' /data1/users/kwagstyl/bigbrain/blocks20/block20-{0:0>4}.mnc\\n'.format(block)\n",
    "            txtname=''\n",
    "        #glimfile=' /data1/users/kwagstyl/bigbrain/volumes/full8_300um.mnc\\n'\n",
    "        dumglim = ' /data1/users/kwagstyl/bigbrain/volumes/full8_1000um.mnc\\n'\n",
    "        with open('glimblock','w') as f:\n",
    "            f.write(dumglim+glimfile)\n",
    "        subprocess.call('/data1/users/kwagstyl/quarantines/Linux-x86_64/bin/print_world_values glimblock coordinates_block.txt block_values_{0:0>4}{1}.txt >/dev/null'.format(block,txtname),shell=True)\n",
    "        #import profiles for block, put into overall profiles matrix\n",
    "        block_intensities=load_intensities('block_values_{0:0>4}{1}.txt'.format(block,txtname))\n",
    "        hemi_intensities[:,blocks[:n_vert]==block]=np.reshape(block_intensities,(n_surfs,verts_in_block),order='F')\n",
    "    #save out overall profiles matrix\n",
    "    np.savetxt(smoothing+'_profiles_'+hemi+'.txt',hemi_intensities.T)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
