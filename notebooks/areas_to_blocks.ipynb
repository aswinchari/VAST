{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import pyminc.volumes.factory as pyminc\n",
    "from skimage.transform import rescale\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def crop_and_resample(arr, crop, scale):\n",
    "    \"\"\"Crop and resize the data\"\"\"\n",
    "    cropped_array=np.zeros((crop[2]-crop[0],crop[3]-crop[1]))\n",
    "    #crop to ensure the box is inside the image. Catches margins outside bigbrain vol.\n",
    "\n",
    "    arr_crop = arr[np.max([0,crop[0]]):np.min([arr.shape[0],crop[2]]), \n",
    "                  np.max([0,crop[1]]):np.min([arr.shape[1],crop[3]])]\n",
    "    cropped_array[np.max([0,-crop[0]]):arr_crop.shape[0]+np.max([0,-crop[0]]),\n",
    "                 np.max([0,-crop[1]]):arr_crop.shape[1]+np.max([0,-crop[1]])] = arr_crop\n",
    "    result=rescale(cropped_array, 1/scale, order=0,anti_aliasing=False,preserve_range=True,multichannel=False)\n",
    "    return result\n",
    "\n",
    "def blockify_from_hdf5(hdf5_filenames,output_dir, margin=20, scale=5):\n",
    "    h5file=h5py.File(hdf5_filenames[0],'r+')\n",
    "    file_labels=h5file['mask'].attrs['labels']\n",
    "    h5file.close()\n",
    "    for area_label in file_labels[1:]:\n",
    "        print('generating block for area: '+area_label.decode())\n",
    "        area_index=np.where(file_labels==area_label)[0][0]\n",
    "        generate_block_for_area(hdf5_filenames, output_dir, area_label, area_index, margin, scale)\n",
    "    return\n",
    "\n",
    "\n",
    "def generate_block_for_area(hdf5_filenames, output_dir, area_label, area_index, margin=20, scale =5):\n",
    "    \"\"\"create a minc block from the hdf5 files\"\"\"\n",
    "    block,limits,sections=calculate_bounding_box(hdf5_filenames,area_index,margin=margin,scale=scale)\n",
    "    template_filename=re.sub(r'\\d\\d\\d\\d','{}',hdf5_filenames[0])\n",
    "    for section in range(block.shape[0]):\n",
    "        im= h5py.File(template_filename.format(sections[section*scale]))['mask']['pyramid']['00'][:]\n",
    "    \n",
    "        im = (im==area_index).astype(int)\n",
    "        #crop and rescale image\n",
    "        scaled=crop_and_resample(im,limits,scale)\n",
    "        block[section]=scaled\n",
    "    \n",
    "    height=im.shape[0]\n",
    "    #invert_y as minc reads from bottom\n",
    "    block=np.flip(block,1)\n",
    "    ## pad in the section direction\n",
    "    block = np.pad(block,((np.round(margin/scale).astype(int),np.round(margin/scale).astype(int)),\n",
    "                          (0,0),(0,0)), 'constant',constant_values=0)\n",
    "    original_origin = np.array([-70.02,-58.6777778, -70.5666667])\n",
    "    start_section=int(sections[0])\n",
    "    y_offset= (start_section-margin)*0.02\n",
    "    z_offset = (height- limits[2]) * 0.021166667\n",
    "    x_offset = limits[1]*0.021166667\n",
    "\n",
    "    crop_shift = np.array([y_offset,z_offset,x_offset])\n",
    "    new_origin= original_origin + crop_shift\n",
    "    steps=(0.02*scale, 0.021166667*scale, 0.021166667*scale)\n",
    "    out_vol = pyminc.volumeFromData(os.path.join(output_dir,area_label.decode()+\"_block.mnc\"), block, dimnames=(\"yspace\", \"zspace\", \"xspace\"), starts=tuple(new_origin), steps=steps, volumeType=\"uint\")\n",
    "    out_vol.writeFile()    \n",
    "    return\n",
    "\n",
    "def calculate_bounding_box(hdf5_filenames,area_index,margin=20, scale=5):\n",
    "    \"\"\" calculate bounding box for a given label.\n",
    "    returns empty box, limits in x/y dimensions and sections to be imported.\n",
    "    a margin is added to mitigate clipping - margin is pixels at 20um\n",
    "    scale determines resolution of bbox. 5 >> 100um\"\"\"\n",
    "    #downsampling scale indicates the level of the pyramid. 07 is 128 times downsampled to 00\n",
    "    downsampling_scale=128\n",
    "    overall_xmin,overall_ymin,overall_xmax,overall_ymax = [np.inf,np.inf,0,0]\n",
    "    #create grid for indices\n",
    "    h5file=h5py.File(hdf5_filenames[0],'r+')\n",
    "    image_mask=h5file['mask']['pyramid']['07'][:]\n",
    "    height, width = image_mask.shape\n",
    "    grid_x, grid_y = np.meshgrid(np.arange(width),np.arange(height))\n",
    "    h5file.close()\n",
    "    \n",
    "    area_sections=[]\n",
    "    for file_name in hdf5_filenames:\n",
    "        \n",
    "        h5file=h5py.File(file_name,'r+')\n",
    "        image_mask=h5file['mask']['pyramid']['07'][:]\n",
    "        #check if area is in the section\n",
    "        if area_index in image_mask:\n",
    "            area_sections.append(re.findall(r'\\d\\d\\d\\d',file_name)[0])\n",
    "            xmin,ymin,xmax,ymax=bbox2(image_mask==area_index)\n",
    "            overall_xmin = min(overall_xmin, xmin)\n",
    "            overall_ymin = min(overall_ymin, ymin)\n",
    "            overall_xmax = max(overall_xmax, xmax)\n",
    "            overall_ymax = max(overall_ymax, ymax)\n",
    "        h5file.close()\n",
    "    #rescale to 20 micron and add margin\n",
    "    limits=np.array([overall_xmin,overall_ymin,overall_xmax,overall_ymax])\n",
    "    limits = limits* downsampling_scale + np.array([-margin,-margin,margin,margin])\n",
    "    \n",
    "    y_length=len(area_sections)\n",
    "    #create limits of the block with margins in ALL directions\n",
    "    dimensions_full_res = np.array([y_length, limits[2]-limits[0], limits[3]-limits[1]])\n",
    "    #downscaled dimensions, rounded down\n",
    "    scaled_dimensions = np.round(dimensions_full_res /scale).astype(int)\n",
    "    #create empty block to fill with data\n",
    "    block=np.zeros((scaled_dimensions.astype(int))).astype(int)\n",
    "    return block,limits, area_sections\n",
    "    \n",
    "    \n",
    "def bbox2(img):\n",
    "    rows = np.any(img, axis=1)\n",
    "    cols = np.any(img, axis=0)\n",
    "    rmin, rmax = np.where(rows)[0][[0, -1]]\n",
    "    cmin, cmax = np.where(cols)[0][[0, -1]]\n",
    "    \n",
    "    return rmin,  cmin, rmax, cmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_filenames=sorted(glob.glob(os.path.join(hdf5_dir,'*.hdf5')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating block for area: area6d_6d1\n",
      "generating block for area: area6d_6d2\n",
      "generating block for area: area6d_6d3\n",
      "generating block for area: auditory_Te10\n",
      "generating block for area: auditory_Te11\n",
      "generating block for area: auditory_Te12\n",
      "generating block for area: auditory_Te3\n",
      "generating block for area: hippocampus_EC\n",
      "generating block for area: ifs_ifj1\n",
      "generating block for area: ifs_ifj2\n",
      "generating block for area: ifs_ifs1\n",
      "generating block for area: ifs_ifs2\n",
      "generating block for area: ifs_ifs3\n",
      "generating block for area: ifs_ifs4\n",
      "generating block for area: pIPS_hIP4\n",
      "generating block for area: pIPS_hIP5\n",
      "generating block for area: pIPS_hIP6\n",
      "generating block for area: pIPS_hIP7\n",
      "generating block for area: pIPS_hIP8\n",
      "generating block for area: pIPS_hOc6\n",
      "generating block for area: pIPS_hPO1\n",
      "generating block for area: sma_presma\n",
      "generating block for area: sma_sma\n",
      "generating block for area: sts_Te4\n",
      "generating block for area: sts_Te5\n"
     ]
    }
   ],
   "source": [
    "blockify_from_hdf5(hdf5_filenames,'../volume_data/area_blocks',margin=50,scale=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:vast] *",
   "language": "python",
   "name": "conda-env-vast-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
