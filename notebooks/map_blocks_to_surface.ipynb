{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import glob\n",
    "import os\n",
    "from scipy.stats import mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "def chunks(l, n):\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]\n",
    "                \n",
    "                \n",
    "\n",
    "\n",
    "def get_neighbours(surfname):\n",
    "    \"\"\"Get neighbours from obj file\"\"\"\n",
    "    Polys=[]\n",
    "    k=0\n",
    "    with open(surfname,'r') as fp:\n",
    "        for i, line in enumerate(fp):\n",
    "            if i==0:\n",
    "    #Number of vertices\n",
    "                n_vert=int(line.split()[6])\n",
    "            elif i==2*n_vert+3:\n",
    "                n_poly=int(line)\n",
    "            elif i>2*n_vert+5:\n",
    "                if not line.strip():\n",
    "                    k=1\n",
    "                elif k==1:\n",
    "                    Polys.extend(line.split())\n",
    "    Polys=list(map(int, Polys))\n",
    "    tris=list(chunks(Polys,3))\n",
    "    neighbours=[[] for i in range(n_vert)]\n",
    "    for tri in tris:\n",
    "        neighbours[tri[0]].extend([tri[1],tri[2]])\n",
    "        neighbours[tri[2]].extend([tri[0],tri[1]])\n",
    "        neighbours[tri[1]].extend([tri[2],tri[0]])\n",
    "#Get unique neighbours\n",
    "    for k in range(len(neighbours)):      \n",
    "        neighbours[k]=f7(neighbours[k])\n",
    "    return np.array(neighbours);\n",
    "\n",
    "def f7(seq):\n",
    "    #returns uniques but in order to retain neighbour triangle relationship\n",
    "    seen = set()\n",
    "    seen_add = seen.add\n",
    "    return [x for x in seq if not (x in seen or seen_add(x))];\n",
    "\n",
    "def compute_islands(area_txtfile,neighbours):\n",
    "    \"\"\"calculates islands with same label value\"\"\"\n",
    "    islands=np.zeros_like(area_txtfile).astype(int)\n",
    "        #array for quick indexing\n",
    "    indices=np.arange(len(area_txtfile))\n",
    "    #k is island counter\n",
    "    k=0\n",
    "    #while some vertices haven't been assigned\n",
    "    while np.sum(islands==0)>0:\n",
    "        k+=1\n",
    "        #start with lowest unassigned vertex\n",
    "        cluster=[np.min(np.where(islands==0)[0])]\n",
    "        #set vertex to island value\n",
    "        islands[cluster]=k\n",
    "        #get label value (i.e. inside or outside label, 1/0)\n",
    "        v_seed_label=area_txtfile[cluster[0]]\n",
    "\n",
    "        old_cluster=0\n",
    "        #while size of island k increases\n",
    "        while np.sum(islands==k)>np.sum(old_cluster):\n",
    "            #calculate new vertices\n",
    "            added_vertices=islands==k-old_cluster\n",
    "            #store for next comparison\n",
    "            old_cluster=islands==k\n",
    "            # for the new vertices\n",
    "            for v in indices[added_vertices]:\n",
    "                #get the neighbours\n",
    "                neighbourhood=np.array(neighbours[v])\n",
    "                #of the neighbours, which are in the same label and not yet part of the island.\n",
    "                #set these to the island value\n",
    "                islands[neighbourhood[np.logical_and(area_txtfile[neighbourhood]==v_seed_label,\n",
    "                                                     islands[neighbourhood]!=k)]]=k\n",
    "    return islands\n",
    "\n",
    "\n",
    "# def tidy_holes(area_txtfile, neighbours,threshold_area=50, iterations=2):\n",
    "#     \"\"\"fills small holes in binary surface annotation file.\n",
    "#     threshold_area is maximum area to be switched.\n",
    "#     iterations is the number of times looped through in case of nested holes\"\"\"\n",
    "#     #create empty surf file to be filled with island indices\n",
    "#     for i in range(iterations):\n",
    "#         islands=np.zeros_like(area_txtfile).astype(int)\n",
    "#         #array for quick indexing\n",
    "#         indices=np.arange(len(area_txtfile))\n",
    "#         #k is island counter\n",
    "#         k=0\n",
    "#         #while some vertices haven't been assigned\n",
    "#         while np.sum(islands==0)>0:\n",
    "#             k+=1\n",
    "#             #start with lowest unassigned vertex\n",
    "#             cluster=[np.min(np.where(islands==0)[0])]\n",
    "#             #set vertex to island value\n",
    "#             islands[cluster]=k\n",
    "#             #get label value (i.e. inside or outside label, 1/0)\n",
    "#             v_seed_label=area_txtfile[cluster[0]]\n",
    "\n",
    "#             old_cluster=0\n",
    "#             #while size of island k increases\n",
    "#             while np.sum(islands==k)>np.sum(old_cluster):\n",
    "#                 #calculate new vertices\n",
    "#                 added_vertices=islands==k-old_cluster\n",
    "#                 #store for next comparison\n",
    "#                 old_cluster=islands==k\n",
    "#                 # for the new vertices\n",
    "#                 for v in indices[added_vertices]:\n",
    "#                     #get the neighbours\n",
    "#                     neighbourhood=np.array(neighbours[v])\n",
    "#                     #of the neighbours, which are in the same label and not yet part of the island.\n",
    "#                     #set these to the island value\n",
    "#                     islands[neighbourhood[np.logical_and(area_txtfile[neighbourhood]==v_seed_label,\n",
    "#                                                          islands[neighbourhood]!=k)]]=k\n",
    "\n",
    "#         #then fill the holes\n",
    "#         new_area=np.copy(area_txtfile).astype(int)\n",
    "#         island_index,counts=np.unique(islands,return_counts=True)\n",
    "#         ordered=np.argsort(counts)\n",
    "#         for ordered_index in ordered:\n",
    "#             if counts[ordered_index]<threshold_area:\n",
    "#                 island_i=island_index[ordered_index]\n",
    "#                 new_area[islands==island_i]=(area_txtfile[islands==island_i][0]-1)*-1\n",
    "#         area_txtfile=new_area\n",
    "#     return new_area\n",
    "\n",
    "def tidy_holes_binary(area_txtfile, neighbours,threshold_area=50, iterations=2):\n",
    "    \"\"\"fills small holes in binary surface annotation file.\n",
    "    threshold_area is maximum area to be switched.\n",
    "    iterations is the number of times looped through in case of nested holes\"\"\"\n",
    "    #create empty surf file to be filled with island indices\n",
    "    for i in range(iterations):\n",
    "        islands=compute_islands(area_txtfile,neighbours)\n",
    "        #then fill the holes\n",
    "        new_area=np.copy(area_txtfile).astype(int)\n",
    "        island_index,counts=np.unique(islands,return_counts=True)\n",
    "        ordered=np.argsort(counts)\n",
    "        for ordered_index in ordered:\n",
    "            if counts[ordered_index]<threshold_area:\n",
    "                island_i=island_index[ordered_index]\n",
    "                new_area[islands==island_i]=(area_txtfile[islands==island_i][0]-1)*-1\n",
    "        area_txtfile=new_area\n",
    "    return new_area\n",
    "\n",
    "def tidy_combined_atlas(combined_areas,neighbours,threshold=100):\n",
    "    \"\"\"fill holes in combined_atlas, including overlapping areas\n",
    "    fills values are the most frequent values on the border of the island\"\"\"\n",
    "    all_areas_islands = compute_islands(combined_areas,neighbours)\n",
    "    island_index,counts=np.unique(all_areas_islands,return_counts=True)\n",
    "    ordered=np.argsort(counts)\n",
    "    overlap_values=np.unique(combined_areas[overlaps])\n",
    "    vertex_indices=np.arange(len(combined_areas))\n",
    "    new_combined_areas=combined_areas.copy()\n",
    "    for ordered_index in ordered:\n",
    "        island_of_interest=all_areas_islands==island_index[ordered_index]\n",
    "        island_value=combined_areas[island_of_interest][0]\n",
    "        #only replace islands of 0s or overlaps\n",
    "        if np.logical_and(counts[ordered_index]<threshold, island_value==0 or (overlaps[island_of_interest]).any()):\n",
    "        \n",
    "            neighbours_island=neighbours[island_of_interest]\n",
    "            long=[]\n",
    "            for n in neighbours_island:\n",
    "                long.extend(n)\n",
    "            unique_neighbours=np.setdiff1d(np.unique(long),vertex_indices[island_of_interest])\n",
    "            new_combined_areas[island_of_interest]=mode(new_combined_areas[unique_neighbours])[0][0]\n",
    "    return new_combined_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir='../surface_data/area_labels'\n",
    "os.makedirs(outdir,exist_ok=True)\n",
    "area_blocks=glob.glob('../volume_data/area_blocks/*.mnc')\n",
    "area_names=[]\n",
    "for ab in area_blocks:\n",
    "    ab=ab.replace('_block.mnc','')\n",
    "    ab=ab.replace('../volume_data/area_blocks/','')\n",
    "    area_names.append(ab)\n",
    "\n",
    "area_names=sorted(area_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auditory_Te3\n",
      "ifs_ifj2\n",
      "pIPS_hIP4\n",
      "area6d_6d2\n",
      "auditory_Te11\n",
      "hippocampus_EC\n",
      "pIPS_hIP7\n",
      "sts_Te4\n",
      "pIPS_hIP8\n",
      "pIPS_hIP6\n",
      "sma_sma\n",
      "pIPS_hIP5\n",
      "sma_presma\n",
      "ifs_ifs3\n",
      "v2\n",
      "sts_Te5\n",
      "auditory_Te10\n",
      "area6d_6d3\n",
      "pIPS_hOc6\n",
      "ifs_ifs1\n",
      "ifs_ifs2\n",
      "ifs_ifj1\n",
      "v1\n",
      "auditory_Te12\n",
      "ifs_ifs4\n",
      "pIPS_hPO1\n",
      "area6d_6d1\n"
     ]
    }
   ],
   "source": [
    "hemis=['right','left']\n",
    "for k,area in enumerate(area_names):\n",
    "    print(area)\n",
    "    for hemi in hemis:\n",
    "        mid_surface_name='../surface_data/obj_surfaces/mid_{}.obj'.format(hemi)\n",
    "\n",
    "        subprocess.call('volume_object_evaluate -nearest_neighbour {} {} {}'.format(area_blocks[k],\n",
    "                                                             mid_surface_name,\n",
    "                                                             os.path.join(outdir,'{}_{}.txt'.format(area,hemi))),shell=True)\n",
    "       \n",
    "\n",
    "  \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auditory_Te3\n",
      "ifs_ifj2\n",
      "pIPS_hIP4\n",
      "area6d_6d2\n",
      "auditory_Te11\n",
      "hippocampus_EC\n",
      "pIPS_hIP7\n",
      "sts_Te4\n",
      "pIPS_hIP8\n",
      "pIPS_hIP6\n",
      "sma_sma\n",
      "pIPS_hIP5\n",
      "sma_presma\n",
      "ifs_ifs3\n",
      "v2\n",
      "sts_Te5\n",
      "auditory_Te10\n",
      "area6d_6d3\n",
      "pIPS_hOc6\n",
      "ifs_ifs1\n",
      "ifs_ifs2\n",
      "ifs_ifj1\n",
      "v1\n",
      "auditory_Te12\n",
      "ifs_ifs4\n",
      "pIPS_hPO1\n",
      "area6d_6d1\n"
     ]
    }
   ],
   "source": [
    "#tidy up individual areas\n",
    "neighbours=get_neighbours(mid_surface_name)\n",
    "for k,area in enumerate(area_names):\n",
    "    print(area)\n",
    "    \n",
    "    for hemi in hemis:\n",
    "       #fill holes\n",
    "        area_txtfile=np.loadtxt(os.path.join(outdir,'{}_{}.txt'.format(area,hemi))).astype(bool)\n",
    "        \n",
    "        tidied=tidy_holes_binary(area_txtfile,neighbours, threshold_area=200,iterations=2)\n",
    "        np.savetxt(os.path.join(outdir,'{}_{}_tidied.txt'.format(area,hemi)),tidied,fmt='%i')\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "area6d_6d1\n",
      "area6d_6d2\n",
      "area6d_6d3\n",
      "auditory_Te10\n",
      "auditory_Te11\n",
      "auditory_Te12\n",
      "auditory_Te3\n",
      "hippocampus_EC\n",
      "ifs_ifj1\n",
      "ifs_ifj2\n",
      "ifs_ifs1\n",
      "ifs_ifs2\n",
      "ifs_ifs3\n",
      "ifs_ifs4\n",
      "pIPS_hIP4\n",
      "pIPS_hIP5\n",
      "pIPS_hIP6\n",
      "pIPS_hIP7\n",
      "pIPS_hIP8\n",
      "pIPS_hOc6\n",
      "pIPS_hPO1\n",
      "sma_presma\n",
      "sma_sma\n",
      "sts_Te4\n",
      "sts_Te5\n",
      "v1\n",
      "v2\n",
      "area6d_6d1\n",
      "area6d_6d2\n",
      "area6d_6d3\n",
      "auditory_Te10\n",
      "auditory_Te11\n",
      "auditory_Te12\n",
      "auditory_Te3\n",
      "hippocampus_EC\n",
      "ifs_ifj1\n",
      "ifs_ifj2\n",
      "ifs_ifs1\n",
      "ifs_ifs2\n",
      "ifs_ifs3\n",
      "ifs_ifs4\n",
      "pIPS_hIP4\n",
      "pIPS_hIP5\n",
      "pIPS_hIP6\n",
      "pIPS_hIP7\n",
      "pIPS_hIP8\n",
      "pIPS_hOc6\n",
      "pIPS_hPO1\n",
      "sma_presma\n",
      "sma_sma\n",
      "sts_Te4\n",
      "sts_Te5\n",
      "v1\n",
      "v2\n"
     ]
    }
   ],
   "source": [
    "#combine areas into single parcellation\n",
    "hemis=['left','right']\n",
    "for hemi in hemis:\n",
    "    area_labels=['null']\n",
    "    mid_surface_name='../surface_data/obj_surfaces/mid_{}.obj'.format(hemi)\n",
    "    neighbours=get_neighbours(mid_surface_name)\n",
    "\n",
    "    combined_areas = np.zeros(len(neighbours))\n",
    "    overlaps = np.zeros(len(tidied)).astype(bool)\n",
    "    for k,area in enumerate(area_names):\n",
    "        print(area)\n",
    "        area_txtfile=np.loadtxt(os.path.join(outdir,'{}_{}_tidied.txt'.format(area,hemi)))\n",
    "        overlaps+= np.logical_and(area_txtfile,combined_areas)\n",
    "        combined_areas+= area_txtfile*(k+1)\n",
    "        area_labels.append(area)\n",
    "    tidied_combined=tidy_combined_atlas(combined_areas, neighbours,threshold=200)\n",
    "    \n",
    "    np.savetxt(os.path.join(outdir,'combined_areas_{}_tidied.txt'.format(hemi)),tidied_combined, fmt='%i')\n",
    "    np.savetxt(os.path.join(outdir,'area_labels_{}.txt'.format(hemi)),area_labels,fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:vast] *",
   "language": "python",
   "name": "conda-env-vast-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
